{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d3ac75",
   "metadata": {},
   "source": [
    "## Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2eba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    return mfccs_mean\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio)\n",
    "play_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio)\n",
    "record_button.place(relx=0.5, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1)\n",
    "predict_button1.place(relx=0.8, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2)\n",
    "predict_button2.place(relx=0.8, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4ac78",
   "metadata": {},
   "source": [
    "## Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "\n",
    "    # Save recorded audio to file\n",
    "    sf.write(output_file, audio_data, sample_rate)\n",
    "\n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    audio_data, _ = sf.read(output_file)\n",
    "    sd.play(audio_data, sample_rate)\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    return mfccs_mean\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "\n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "\n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "\n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "\n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "\n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "\n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "\n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "\n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "\n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "\n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "\n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "\n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio)\n",
    "play_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio)\n",
    "record_button.place(relx=0.5, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1)\n",
    "predict_button1.place(relx=0.8, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2)\n",
    "predict_button2.place(relx=0.8, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bddbb28",
   "metadata": {},
   "source": [
    "## Try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43adcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (180, 1))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio)\n",
    "play_button.place(relx=0.5, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio)\n",
    "record_button.place(relx=0.5, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1)\n",
    "predict_button1.place(relx=0.8, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2)\n",
    "predict_button2.place(relx=0.8, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1bbb74",
   "metadata": {},
   "source": [
    "## Try 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (180, 1))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio)\n",
    "play_button.place(relx=0.8, rely=0.4, anchor=tk.CENTER)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio)\n",
    "record_button.place(relx=0.8, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1)\n",
    "predict_button1.place(relx=0.8, rely=0.8, anchor=tk.CENTER)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2)\n",
    "predict_button2.place(relx=0.8, rely=1.0, anchor=tk.CENTER)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce76fd",
   "metadata": {},
   "source": [
    "## Try 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e92282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (180, 1))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    audio_features = np.expand_dims(audio_features, axis=0)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio)\n",
    "play_button.place(relx=0.95, rely=0.1, anchor=tk.NE)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio)\n",
    "record_button.place(relx=0.95, rely=0.3, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1)\n",
    "predict_button1.place(relx=0.95, rely=0.5, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2)\n",
    "predict_button2.place(relx=0.95, rely=0.7, anchor=tk.NE)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01a19f",
   "metadata": {},
   "source": [
    "## Try 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e515cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio)\n",
    "play_button.place(relx=1.0, rely=0.0, anchor=tk.NE)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio)\n",
    "record_button.place(relx=1.0, rely=0.2, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1)\n",
    "predict_button1.place(relx=1.0, rely=0.4, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2)\n",
    "predict_button2.place(relx=1.0, rely=0.6, anchor=tk.NE)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6cbb98",
   "metadata": {},
   "source": [
    "## Try 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=2)\n",
    "play_button.place(relx=1.0, rely=0.0, anchor=tk.NE)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=2)\n",
    "record_button.place(relx=1.0, rely=0.2, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=2)\n",
    "predict_button1.place(relx=1.0, rely=0.4, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=2)\n",
    "predict_button2.place(relx=1.0, rely=0.6, anchor=tk.NE)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40be80",
   "metadata": {},
   "source": [
    "## Try 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02da500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=2, bg=\"blue\")\n",
    "play_button.place(relx=1.0, rely=0.0, anchor=tk.NE)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=2, bg=\"blue\")\n",
    "record_button.place(relx=1.0, rely=0.2, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=2, bg=\"blue\")\n",
    "predict_button1.place(relx=1.0, rely=0.4, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=2, bg=\"blue\")\n",
    "predict_button2.place(relx=1.0, rely=0.6, anchor=tk.NE)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb91d45",
   "metadata": {},
   "source": [
    "## Try 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"blue\")\n",
    "play_button.place(relx=1.0, rely=0.0, anchor=tk.NE)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"blue\")\n",
    "record_button.place(relx=1.0, rely=0.2, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"blue\")\n",
    "predict_button1.place(relx=1.0, rely=0.4, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"blue\")\n",
    "predict_button2.place(relx=1.0, rely=0.6, anchor=tk.NE)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e841c41",
   "metadata": {},
   "source": [
    "## Try 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "play_button.place(relx=1.0, rely=0.0, anchor=tk.NE)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "record_button.place(relx=1.0, rely=0.2, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button1.place(relx=1.0, rely=0.4, anchor=tk.NE)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button2.place(relx=1.0, rely=0.6, anchor=tk.NE)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c2d30",
   "metadata": {},
   "source": [
    "## Try 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f01a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"600x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Load and resize the character image\n",
    "character_image = Image.open(r\"C:\\Users\\Acer pc\\OneDrive - Manav Rachna Education Institutions\\Pictures\\Screenshots\\pngtree-single-person-character-in-vector-png-image_2194492.jpg\")\n",
    "character_image = character_image.resize((200, 200), Image.ANTIALIAS)\n",
    "character_photo = ImageTk.PhotoImage(character_image)\n",
    "\n",
    "# Create Label to display the character image\n",
    "character_label = tk.Label(root, image=character_photo)\n",
    "character_label.pack(side=tk.LEFT)\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "play_button.pack(side=tk.TOP, pady=20)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "record_button.pack(side=tk.TOP)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button1.pack(side=tk.TOP, pady=20)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button2.pack(side=tk.TOP)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b56d3",
   "metadata": {},
   "source": [
    "## Try 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"600x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Load and resize the character image\n",
    "character_image = Image.open(\"C:/Users/Acer pc/OneDrive - Manav Rachna Education Institutions/Pictures/Screenshots/pngtree-single-person-character-in-vector-png-image_2194492.jpg\")\n",
    "character_image = character_image.resize((400, 400), Image.ANTIALIAS)\n",
    "character_photo = ImageTk.PhotoImage(character_image)\n",
    "\n",
    "# Create Label to display the character image\n",
    "character_label = tk.Label(root, image=character_photo)\n",
    "character_label.pack(side=tk.LEFT)\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "play_button.pack(side=tk.TOP, pady=50)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "record_button.pack(side=tk.TOP, pady=30)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button1.pack(side=tk.TOP, pady=20)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button2.pack(side=tk.TOP)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce75fce",
   "metadata": {},
   "source": [
    "## Try 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"600x500\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Load and resize the character image\n",
    "character_image = Image.open(\"C:/Users/Acer pc/OneDrive - Manav Rachna Education Institutions/Pictures/Screenshots/pngtree-single-person-character-in-vector-png-image_2194492.jpg\")\n",
    "character_image = character_image.resize((400, 400), Image.ANTIALIAS)\n",
    "character_photo = ImageTk.PhotoImage(character_image)\n",
    "\n",
    "# Create Label to display the character image\n",
    "character_label = tk.Label(root, image=character_photo)\n",
    "character_label.pack(side=tk.LEFT)\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "play_button.pack(side=tk.TOP, pady=50)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "record_button.pack(side=tk.TOP)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button1.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button2.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321a809",
   "metadata": {},
   "source": [
    "## Try 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"600x500\")\n",
    "\n",
    "# Set background color\n",
    "root.configure(bg=\"light gray\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Load and resize the character image\n",
    "character_image = Image.open(\"C:/Users/Acer pc/OneDrive - Manav Rachna Education Institutions/Pictures/Screenshots/pngtree-single-person-character-in-vector-png-image_2194492.jpg\")\n",
    "character_image = character_image.resize((400, 400), Image.ANTIALIAS)\n",
    "character_photo = ImageTk.PhotoImage(character_image)\n",
    "\n",
    "# Create Label to display the character image\n",
    "character_label = tk.Label(root, image=character_photo)\n",
    "character_label.pack(side=tk.LEFT)\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "play_button.pack(side=tk.TOP, pady=50)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "record_button.pack(side=tk.TOP)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button1.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button2.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfd187",
   "metadata": {},
   "source": [
    "## Try 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55debba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer pc\\AppData\\Local\\Temp\\ipykernel_14524\\590798830.py:108: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  character_gif = character_gif.resize((400, 400), resample=Image.LANCZOS)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from PIL import Image, ImageTk, ImageSequence\n",
    "\n",
    "# Constants for audio recording\n",
    "duration = 3  # Duration of recording in seconds\n",
    "sample_rate = 22050  # Sample rate of audio\n",
    "output_file = \"recorded_audio.wav\"  # Output file path\n",
    "\n",
    "# Emotions dictionary\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Prediction\")\n",
    "root.geometry(\"600x500\")\n",
    "\n",
    "# Set background color\n",
    "root.configure(bg=\"light gray\")\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    messagebox.showinfo(\"Recording\", \"Recording started. Please speak into the microphone for {} seconds.\".format(duration))\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, blocking=True)\n",
    "    messagebox.showinfo(\"Recording\", \"Recording finished.\")\n",
    "    \n",
    "    # Save recorded audio to file\n",
    "    sd.write(output_file, audio_data, sample_rate)\n",
    "    \n",
    "    # Play the recorded audio\n",
    "    play_audio()\n",
    "\n",
    "# Function to play recorded audio\n",
    "def play_audio():\n",
    "    messagebox.showinfo(\"Playback\", \"Playing recorded audio...\")\n",
    "    display(Audio(output_file))\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_feature(audio_data):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_resized = np.resize(mfccs, (1, 180))\n",
    "    return mfccs_resized\n",
    "\n",
    "# Function to predict using the first model\n",
    "def predict_model1():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 1...\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model('model1.h5')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = emotions[str(np.argmax(prediction)+1).zfill(2)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Function to predict using the second loaded model\n",
    "def predict_model2():\n",
    "    messagebox.showinfo(\"Prediction\", \"Predicting using Model 2...\")\n",
    "    \n",
    "    # Load the model\n",
    "    loaded_model = joblib.load('model_file.pkl')\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(output_file, sr=sample_rate)\n",
    "    \n",
    "    # Extract audio features\n",
    "    audio_features = extract_feature(audio_data)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = loaded_model.predict(audio_features)\n",
    "    \n",
    "    # Get the predicted emotion label\n",
    "    predicted_emotion_label = observed_emotions[np.argmax(prediction)]\n",
    "    \n",
    "    # Show the predicted emotion result\n",
    "    messagebox.showinfo(\"Prediction Result\", \"The predicted emotion is: {}\".format(predicted_emotion_label))\n",
    "\n",
    "# Load and resize the character GIF\n",
    "character_gif = Image.open(\"C:/Users/Acer pc/Downloads/image_processing20190902-32729-mcbpca.gif\")\n",
    "character_gif = character_gif.resize((400, 400), resample=Image.LANCZOS)\n",
    "frames = []\n",
    "for frame in ImageSequence.Iterator(character_gif):\n",
    "    frames.append(frame.copy())\n",
    "character_gif.close()\n",
    "\n",
    "# Create Label to display the character GIF\n",
    "character_label = tk.Label(root)\n",
    "character_label.pack(side=tk.LEFT)\n",
    "\n",
    "# Function to animate the character GIF\n",
    "def animate_gif(frame_index=0):\n",
    "    frame = frames[frame_index]\n",
    "    photo = ImageTk.PhotoImage(frame)\n",
    "    character_label.configure(image=photo)\n",
    "    character_label.image = photo\n",
    "    frame_index = (frame_index + 1) % len(frames)\n",
    "    root.after(100, animate_gif, frame_index)\n",
    "\n",
    "# Create Play button\n",
    "play_button = tk.Button(root, text=\"Play\", command=play_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "play_button.pack(side=tk.TOP, pady=50)\n",
    "\n",
    "# Create Record button\n",
    "record_button = tk.Button(root, text=\"Record\", command=record_audio, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "record_button.pack(side=tk.TOP)\n",
    "\n",
    "# Create Predict button for Model 1\n",
    "predict_button1 = tk.Button(root, text=\"Predict Model 1\", command=predict_model1, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button1.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "# Create Predict button for Model 2\n",
    "predict_button2 = tk.Button(root, text=\"Predict Model 2\", command=predict_model2, width=15, height=3, bg=\"light blue\", highlightbackground=\"blue\", bd=2)\n",
    "predict_button2.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "# Start animating the character GIF\n",
    "animate_gif()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb6bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53890bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c7793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
